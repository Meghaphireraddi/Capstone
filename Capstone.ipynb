{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/opt/anaconda3/bin/python3.7'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/anaconda3/bin/python3.7'\n",
    "os.environ[\"SPARK_HOME\"] = '/opt/cloudera/parcels/CDH/lib/spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession,SQLContext, Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() #Boiler\n",
    "for part in cwd.split('/'):\n",
    "    if part.lower().startswith('test6'):\n",
    "        user_id = part.title()\n",
    "    user_id = part.title().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anabig114241 : Hive Integration'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_name = '{0} : Hive Integration'.format(user_id)\n",
    "app_name \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"app_name\").config(\"spark.sql.catalogImplementation=hive\").enableHiveSupport().getOrCreate() #Singleton instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdfs_anabig114241(Capstone):\n",
    "    my_hdfs = '/user/{0}'.format(user_id.lower())\n",
    "    return os.path.join(my_hdfs,Capstone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = (SparkSession.builder.appName(\"app_name\").config(\"hive.metastore.uris\",\"thrift://ip-10-1-2-24.ap-south-1.compute.internal:9083\").enableHiveSupport().getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/hadoop/lib/native'),\n",
       " ('spark.driver.host', 'ip-10-1-1-204.ap-south-1.compute.internal'),\n",
       " ('spark.yarn.appMasterEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.yarn.jars',\n",
       "  'local:/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark/jars/*,local:/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark/hive/*'),\n",
       " ('spark.sql.catalogImplementation=hive', 'None'),\n",
       " ('spark.sql.queryExecutionListeners',\n",
       "  'com.cloudera.spark.lineage.NavigatorQueryListener'),\n",
       " ('spark.app.id', 'application_1652166004796_3274'),\n",
       " ('spark.yarn.am.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/hadoop/lib/native'),\n",
       " ('spark.driver.port', '43262'),\n",
       " ('spark.ui.killEnabled', 'true'),\n",
       " ('spark.lineage.log.dir', '/var/log/spark/lineage'),\n",
       " ('spark.eventLog.dir', 'hdfs://nameservice1/user/spark/applicationHistory'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '60'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.io.encryption.enabled', 'false'),\n",
       " ('spark.authenticate', 'false'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://ip-10-1-1-204.ap-south-1.compute.internal:6066/proxy/application_1652166004796_3274'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.yarn.historyServer.address',\n",
       "  'http://ip-10-1-1-204.ap-south-1.compute.internal:18088'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.network.crypto.enabled', 'false'),\n",
       " ('hive.metastore.uris',\n",
       "  'thrift://ip-10-1-2-24.ap-south-1.compute.internal:9083'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.historyServer.allowTracking', 'true'),\n",
       " ('spark.executorEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/hadoop/lib/native'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.dynamicAllocation.schedulerBacklogTimeout', '1'),\n",
       " ('spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.shuffle.service.port', '7337'),\n",
       " ('spark.app.name', 'app_name'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'ip-10-1-1-204.ap-south-1.compute.internal'),\n",
       " ('spark.lineage.enabled', 'true'),\n",
       " ('spark.extraListeners', 'com.cloudera.spark.lineage.NavigatorAppListener'),\n",
       " ('spark.yarn.config.gatewayPath', '/opt/cloudera/parcels'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.log.persistToDfs.enabled', 'true'),\n",
       " ('spark.ui.enabled', 'false'),\n",
       " ('spark.dynamicAllocation.minExecutors', '0'),\n",
       " ('spark.yarn.config.replacementPath', '{{HADOOP_COMMON_HOME}}/../../..'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1652166004796_3274'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark/python/lib/pyspark.zip'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.log.dfsDir', '/user/spark/driverLogs')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sparkContext.getConf().getAll() #configurations\n",
    "sparkSession.sparkContext.getConf().getAll() #configurations\n",
    "# can be over-written using below\n",
    "# SparkSession.builder.appName(app_name).config(\"spark.sql.warehouse.dir\", \"warehouse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_tbl = \"CREATE TABLE IF NOT EXISTS employees{}(age STRING, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\\n'\"\n",
    "sparkSession.sql(create_tbl.format(user_id.upper()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        databaseName|\n",
      "+--------------------+\n",
      "|           01may2022|\n",
      "|           09may2022|\n",
      "|             09may22|\n",
      "|           10nov2011|\n",
      "|           12oct2022|\n",
      "|         14april2022|\n",
      "|14mar2022weekdaymorn|\n",
      "|     16jan2022anjand|\n",
      "|          18bd1a0420|\n",
      "|             1carddb|\n",
      "|             26march|\n",
      "| 555555555555555555d|\n",
      "|                  a1|\n",
      "|                  aa|\n",
      "|         aadityaalab|\n",
      "|          aadityalab|\n",
      "|   aaron_assignments|\n",
      "|              aaronj|\n",
      "|           aaronjude|\n",
      "|         aaronjudedz|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sparkSession.sql('show databases').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sparkSession.sql('use alabs').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|         tableName|isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "|   alabs|              2013|      false|\n",
      "|   alabs|        aveintrest|      false|\n",
      "|   alabs|              avg1|      false|\n",
      "|   alabs|   avgintrestrate2|      false|\n",
      "|   alabs|          building|      false|\n",
      "|   alabs|         building1|      false|\n",
      "|   alabs|        department|      false|\n",
      "|   alabs|       departments|      false|\n",
      "|   alabs|      departments1|      false|\n",
      "|   alabs|          dept_emp|      false|\n",
      "|   alabs|      dept_manager|      false|\n",
      "|   alabs|           detail1|      false|\n",
      "|   alabs|           details|      false|\n",
      "|   alabs|         employees|      false|\n",
      "|   alabs|             first|      false|\n",
      "|   alabs|          grademix|      false|\n",
      "|   alabs|         grademix1|      false|\n",
      "|   alabs|         grademix3|      false|\n",
      "|   alabs|historyreturngrade|      false|\n",
      "|   alabs|              hvac|      false|\n",
      "+--------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sparkSession.sql('show tables').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|dept_no|         dept_name|\n",
      "+-------+------------------+\n",
      "|   d001|         Marketing|\n",
      "|   d002|           Finance|\n",
      "|   d003|   Human Resources|\n",
      "|   d004|        Production|\n",
      "|   d005|       development|\n",
      "|   d006|Quality Management|\n",
      "|   d007|             Sales|\n",
      "|   d008|          Research|\n",
      "|   d009|  Customer Service|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select * from departments1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|title_id|             title|\n",
      "+--------+------------------+\n",
      "|   e0001|Assistant Engineer|\n",
      "|   e0002|          Engineer|\n",
      "|   e0003|   Senior Engineer|\n",
      "|   e0004|  Technique Leader|\n",
      "|   m0001|           Manager|\n",
      "|   s0001|             Staff|\n",
      "|   s0002|      Senior Staff|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select * from titles\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing employee number, last name, first name, sex, and salary for each employee1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+---+------+\n",
      "|emp_no|  last_name|first_name|sex|salary|\n",
      "+------+-----------+----------+---+------+\n",
      "| 10001|    Facello|    Georgi|  M| 60117|\n",
      "| 10002|     Simmel|   Bezalel|  F| 65828|\n",
      "| 10003|    Bamford|     Parto|  M| 40006|\n",
      "| 10004|    Koblick| Chirstian|  M| 40054|\n",
      "| 10005|   Maliniak|   Kyoichi|  M| 78228|\n",
      "| 10006|    Preusig|    Anneke|  F| 40000|\n",
      "| 10007|  Zielinski|   Tzvetan|  F| 56724|\n",
      "| 10008|   Kalloufi|    Saniya|  M| 46671|\n",
      "| 10009|       Peac|    Sumant|  F| 60929|\n",
      "| 10010|   Piveteau| Duangkaew|  F| 72488|\n",
      "| 10011|      Sluis|      Mary|  F| 42365|\n",
      "| 10012|  Bridgland|  Patricio|  M| 40000|\n",
      "| 10013|     Terkki| Eberhardt|  M| 40000|\n",
      "| 10014|      Genin|     Berni|  M| 46168|\n",
      "| 10015|  Nooteboom|  Guoxiang|  M| 40000|\n",
      "| 10016|Cappelletti|  Kazuhito|  M| 70889|\n",
      "| 10017|  Bouloucos| Cristinel|  F| 71380|\n",
      "| 10018|       Peha|  Kazuhide|  F| 55881|\n",
      "| 10019|    Haddadi|   Lillian|  M| 44276|\n",
      "| 10020|    Warwick|    Mayuko|  M| 40000|\n",
      "+------+-----------+----------+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select s.emp_no, e.last_name, e.first_name, e.sex, s.salary from employees as e inner join salaries as s on s.emp_no = e.emp_no order by s.emp_no\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing first name, last  name, and hire date for employees who were hired in 1986\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|emp_no|last_name|first_name| hire_date|\n",
      "+------+---------+----------+----------+\n",
      "| 10081|    Rosen|  Zhongwei|10/30/1986|\n",
      "| 10150|    Perng|  Zhenbing|11/16/1986|\n",
      "| 10201|  Kavraki|     Idoia|11/22/1986|\n",
      "| 10238|     Gire| Mototsugu|11/19/1986|\n",
      "| 10268|   Siochi|    Nishit|12/17/1986|\n",
      "| 10317|    Birge|      Arie|12/10/1986|\n",
      "| 10361|    Sidou|     Seshu|10/23/1986|\n",
      "| 10435| Tagansky|    Marsha|12/19/1986|\n",
      "| 10522| Cesareni|     Marke|12/12/1986|\n",
      "| 10533|Smailagic| Mohamadou|10/31/1986|\n",
      "| 10701| Zolotykh| Hyuncheol|10/27/1986|\n",
      "| 10807| Zallocco|  Munehiro|10/23/1986|\n",
      "| 10832|  Bergere|     Hidde|10/11/1986|\n",
      "| 10856|     Peck| Sreenivas|12/31/1986|\n",
      "| 10962|   Kugler|    Naraig|12/16/1986|\n",
      "| 10975| Birnbaum| Peternela|10/31/1986|\n",
      "| 11010| Narwekar|    Jaques|12/18/1986|\n",
      "| 11012|Speckmann|   Taegyun|12/28/1986|\n",
      "| 11059|  Jarecki|    Shawna|11/17/1986|\n",
      "| 11085|  Thummel|   Hailing|11/27/1986|\n",
      "+------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\" select emp_no, last_name, first_name, hire_date from employees where cast(substr( hire_date,7,4) as int) = 1986 \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # A list showing the manager of each department with the following information: department number, department name, the manager's employee number, last name, first name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+------------+-----------+\n",
      "|dept_no|         dept_name|emp_no|   last_name| first_name|\n",
      "+-------+------------------+------+------------+-----------+\n",
      "|   d001|         Marketing|110022|  Markovitch|  Margareta|\n",
      "|   d002|           Finance|110085|       Alpin|       Ebru|\n",
      "|   d003|   Human Resources|110183|Ossenbruggen|    Shirish|\n",
      "|   d004|        Production|110303|     Wegerle|  Krassimir|\n",
      "|   d005|       development|110511|    Hagimont|   DeForest|\n",
      "|   d006|Quality Management|110725|     Onuegbe|  Peternela|\n",
      "|   d007|             Sales|111035|   Kaelbling|Przemyslawa|\n",
      "|   d008|          Research|111400|     Staelin|       Arie|\n",
      "|   d009|  Customer Service|111692| Butterworth|      Tonny|\n",
      "+-------+------------------+------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select distinct  dept_manager.dept_no, departments1.dept_name, dept_manager.emp_no, employees.last_name, employees.first_name from dept_manager inner join departments1 on dept_manager.dept_no= departments1.dept_no inner join employees on dept_manager.emp_no = employees.emp_no order by dept_manager.dept_no\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing the department of each employee with the following information: employee number, last name, first name, and department name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+------------------+\n",
      "|emp_no|  last_name|first_name|         dept_name|\n",
      "+------+-----------+----------+------------------+\n",
      "| 10001|    Facello|    Georgi|       development|\n",
      "| 10002|     Simmel|   Bezalel|             Sales|\n",
      "| 10003|    Bamford|     Parto|        Production|\n",
      "| 10004|    Koblick| Chirstian|        Production|\n",
      "| 10005|   Maliniak|   Kyoichi|   Human Resources|\n",
      "| 10006|    Preusig|    Anneke|       development|\n",
      "| 10007|  Zielinski|   Tzvetan|          Research|\n",
      "| 10008|   Kalloufi|    Saniya|       development|\n",
      "| 10009|       Peac|    Sumant|Quality Management|\n",
      "| 10010|   Piveteau| Duangkaew|        Production|\n",
      "| 10010|   Piveteau| Duangkaew|Quality Management|\n",
      "| 10011|      Sluis|      Mary|  Customer Service|\n",
      "| 10012|  Bridgland|  Patricio|       development|\n",
      "| 10013|     Terkki| Eberhardt|   Human Resources|\n",
      "| 10014|      Genin|     Berni|       development|\n",
      "| 10015|  Nooteboom|  Guoxiang|          Research|\n",
      "| 10016|Cappelletti|  Kazuhito|             Sales|\n",
      "| 10017|  Bouloucos| Cristinel|         Marketing|\n",
      "| 10018|       Peha|  Kazuhide|        Production|\n",
      "| 10018|       Peha|  Kazuhide|       development|\n",
      "+------+-----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select distinct  employees.emp_no, employees.last_name, employees.first_name, departments1.dept_name from employees left join dept_emp on employees.emp_no = dept_emp.emp_no inner join departments1 on dept_emp.dept_no = departments1.dept_no order by employees.emp_no\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing first name, last name, and sex for employees whose first name is \"Hercules\" and last names begin with \"B.“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|    last_name|first_name|\n",
      "+-------------+----------+\n",
      "|         Baak|  Hercules|\n",
      "|         Baer|  Hercules|\n",
      "|         Bahr|  Hercules|\n",
      "|         Bail|  Hercules|\n",
      "|         Bain|  Hercules|\n",
      "|   Baranowski|  Hercules|\n",
      "|     Barreiro|  Hercules|\n",
      "|      Basagni|  Hercules|\n",
      "|     Benantar|  Hercules|\n",
      "|   Benzmuller|  Hercules|\n",
      "|Bernardinello|  Hercules|\n",
      "|    Bernatsky|  Hercules|\n",
      "|      Berstel|  Hercules|\n",
      "|        Biran|  Hercules|\n",
      "|        Birge|  Hercules|\n",
      "|        Biron|  Hercules|\n",
      "|      Bisiani|  Hercules|\n",
      "|       Bodoff|  Hercules|\n",
      "|      Brendel|  Hercules|\n",
      "|      Buchter|  Hercules|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select last_name, first_name from employees where (first_name = 'Hercules') and (lower(last_name) like 'b%') order by last_name\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing all employees in the Sales department, including their employee number, last name, first name, and department name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+----------+---------+\n",
      "|emp_no|   last_name|first_name|dept_name|\n",
      "+------+------------+----------+---------+\n",
      "| 10002|      Simmel|   Bezalel|    Sales|\n",
      "| 10016| Cappelletti|  Kazuhito|    Sales|\n",
      "| 10034|        Swan|     Bader|    Sales|\n",
      "| 10041|      Lenart|       Uri|    Sales|\n",
      "| 10050|      Dredge|   Yinghua|    Sales|\n",
      "| 10053|    Zschoche|    Sanjiv|    Sales|\n",
      "| 10060| Billingsley|  Breannda|    Sales|\n",
      "| 10061|      Herber|       Tse|    Sales|\n",
      "| 10068|     Brattka|  Charlene|    Sales|\n",
      "| 10087|     Eugenio|   Xinglin|    Sales|\n",
      "| 10088|    Syrzycki|  Jungsoon|    Sales|\n",
      "| 10089|Flasterstein| Sudharsan|    Sales|\n",
      "| 10093|     Desikan|   Sailaja|    Sales|\n",
      "| 10095|      Morton|    Hilari|    Sales|\n",
      "| 10099|     Sullins|    Valter|    Sales|\n",
      "| 10101|      Heyers|     Perla|    Sales|\n",
      "| 10107|        Baca|      Dung|    Sales|\n",
      "| 10125|     Hiltgen|     Syozo|    Sales|\n",
      "| 10136|    Pintelas|    Zissis|    Sales|\n",
      "| 10148|       Azumi|    Douadi|    Sales|\n",
      "+------+------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select employees.emp_no, employees.last_name, employees.first_name, departments1.dept_name from employees inner join dept_emp on dept_emp.emp_no = employees.emp_no inner join departments1 on dept_emp.dept_no= departments1.dept_no where lower(departments1.dept_name) = 'sales'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing all employees in the Sales and Development departments, including their employee number, last name, first name, and department name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-----------+\n",
      "|emp_no|  last_name|first_name|  dept_name|\n",
      "+------+-----------+----------+-----------+\n",
      "| 10001|    Facello|    Georgi|development|\n",
      "| 10002|     Simmel|   Bezalel|      Sales|\n",
      "| 10006|    Preusig|    Anneke|development|\n",
      "| 10008|   Kalloufi|    Saniya|development|\n",
      "| 10012|  Bridgland|  Patricio|development|\n",
      "| 10014|      Genin|     Berni|development|\n",
      "| 10016|Cappelletti|  Kazuhito|      Sales|\n",
      "| 10018|       Peha|  Kazuhide|development|\n",
      "| 10021|       Erde|     Ramzi|development|\n",
      "| 10022|     Famili|    Shahaf|development|\n",
      "| 10023| Montemayor|     Bojan|development|\n",
      "| 10025|     Heyers| Prasadram|development|\n",
      "| 10027|    Reistad|    Divier|development|\n",
      "| 10028|   Tempesti|  Domenick|development|\n",
      "| 10031|     Joslin|   Karsten|development|\n",
      "| 10034|       Swan|     Bader|      Sales|\n",
      "| 10037|   Makrucki|   Pradeep|development|\n",
      "| 10040|    Meriste|     Weiyi|development|\n",
      "| 10041|     Lenart|       Uri|      Sales|\n",
      "| 10043|    Tzvieli|    Yishay|development|\n",
      "+------+-----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select employees.emp_no, employees.last_name, employees.first_name, departments1.dept_name from employees inner join dept_emp on dept_emp.emp_no = employees.emp_no inner join departments1 on dept_emp.dept_no= departments1.dept_no where (lower(departments1.dept_name) = 'sales') or (lower(departments1.dept_name) = 'development')\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list showing the frequency count of employee last names, in descending order. ( i.e., how many employees share each last name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|  last_name|Frequency|\n",
      "+-----------+---------+\n",
      "|       Baba|      226|\n",
      "|     Gelosh|      223|\n",
      "|      Coorg|      223|\n",
      "|    Sudbeck|      222|\n",
      "|     Farris|      222|\n",
      "|     Adachi|      221|\n",
      "|     Osgood|      220|\n",
      "|     Neiman|      218|\n",
      "|    Mandell|      218|\n",
      "|     Masada|      218|\n",
      "|Boudaillier|      217|\n",
      "|    Wendorf|      217|\n",
      "|     Mahnke|      216|\n",
      "|    Solares|      216|\n",
      "|     Pettis|      216|\n",
      "|   Cummings|      216|\n",
      "|     Emmart|      215|\n",
      "|    Kulisch|      215|\n",
      "|   Birjandi|      215|\n",
      "| Maksimenko|      215|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\"select last_name,count(last_name) as Frequency from employees group by last_name order by Frequency desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
